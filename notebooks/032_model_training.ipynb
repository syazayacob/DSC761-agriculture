{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7663f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318b4c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 00:18:10.584784: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-19 00:18:16.255219: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-19 00:18:18.834037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752884303.469193    5535 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752884304.570964    5535 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752884313.218295    5535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752884313.218332    5535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752884313.218337    5535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752884313.218340    5535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-19 00:18:33.704798: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# ANN: TensorFlow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91d59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create directories ===\n",
    "os.makedirs(\"../models/improve\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2923b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load cleaned & log-transformed data ===\n",
    "#df = pd.read_csv(\"../data/improve/crop_data_pivot_log.csv\")\n",
    "\n",
    "url = \"https://huggingface.co/datasets/syazayacob/crop_data_pivot_log/resolve/main/crop_data_pivot_log.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1c067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define target variables ===\n",
    "targets = [\"Production\", \"Area harvested\", \"Yield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4079925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define ANN training function ===\n",
    "def train_ann(X_train, y_train, X_test, y_test, model_path):\n",
    "    input_layer = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(64, activation='relu')(input_layer)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              validation_split=0.2,\n",
    "              epochs=50,\n",
    "              batch_size=32,\n",
    "              callbacks=[es],\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    model.save(f\"{model_path}.h5\")\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262b1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Training models to predict: Production\n",
      "üîπ Training ANN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 00:18:52.358558: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3599/3599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Training Random Forest...\n",
      "üîπ Training Linear Regression...\n",
      "üîπ Training XGBoost...\n",
      "\n",
      "üìå Training models to predict: Area harvested\n",
      "üîπ Training ANN...\n",
      "\u001b[1m3599/3599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Training Random Forest...\n",
      "üîπ Training Linear Regression...\n",
      "üîπ Training XGBoost...\n",
      "\n",
      "üìå Training models to predict: Yield\n",
      "üîπ Training ANN...\n",
      "\u001b[1m3599/3599\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Training Random Forest...\n",
      "üîπ Training Linear Regression...\n",
      "üîπ Training XGBoost...\n",
      "\n",
      "‚úÖ All models trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# === Training loop for each target ===\n",
    "results = []\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\nüìå Training models to predict: {target}\")\n",
    "\n",
    "    # Features = other targets + 'Year'\n",
    "    feature_cols = [col for col in targets if col != target] + [\"Year\"]\n",
    "\n",
    "    # Drop rows with missing target/features\n",
    "    data = df.dropna(subset=[target] + feature_cols).copy()\n",
    "    X = data[feature_cols]\n",
    "    y = data[target]\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # === Train ANN ===\n",
    "    print(\"üîπ Training ANN...\")\n",
    "    y_pred_ann, model_ann = train_ann(X_train, y_train, X_test, y_test, f\"../models/{target}_ANN\")\n",
    "    joblib.dump(scaler, f\"../models/{target}_ANN_scaler.pkl\", compress=3)\n",
    "\n",
    "    mse_ann = mean_squared_error(y_test, y_pred_ann)\n",
    "    r2_ann = r2_score(y_test, y_pred_ann)\n",
    "\n",
    "    results.append({\"Target\": target, \"Model\": \"ANN\", \"MSE\": mse_ann, \"R2\": r2_ann})\n",
    "\n",
    "    # === Train Random Forest ===\n",
    "    print(\"üîπ Training Random Forest...\")\n",
    "    rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    joblib.dump({\"model\": rf, \"scaler\": scaler}, f\"../models/{target}_RandomForest.pkl\", compress=3)\n",
    "\n",
    "    results.append({\"Target\": target, \"Model\": \"RandomForest\", \"MSE\": mean_squared_error(y_test, y_pred_rf), \"R2\": r2_score(y_test, y_pred_rf)})\n",
    "\n",
    "    # === Train Linear Regression ===\n",
    "    print(\"üîπ Training Linear Regression...\")\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "    joblib.dump({\"model\": lr, \"scaler\": scaler}, f\"../models/{target}_LinearRegression.pkl\")\n",
    "\n",
    "    results.append({\"Target\": target, \"Model\": \"LinearRegression\", \"MSE\": mean_squared_error(y_test, y_pred_lr), \"R2\": r2_score(y_test, y_pred_lr)})\n",
    "\n",
    "    # === Train XGBoost ===\n",
    "    print(\"üîπ Training XGBoost...\")\n",
    "    xg = XGBRegressor(n_estimators=50, learning_rate=0.1, random_state=42)\n",
    "    xg.fit(X_train, y_train)\n",
    "    y_pred_xg = xg.predict(X_test)\n",
    "    joblib.dump({\"model\": xg, \"scaler\": scaler}, f\"../models/{target}_XGBoost.pkl\")\n",
    "\n",
    "    results.append({\"Target\": target, \"Model\": \"XGBoost\", \"MSE\": mean_squared_error(y_test, y_pred_xg), \"R2\": r2_score(y_test, y_pred_xg)})\n",
    "\n",
    "print(\"\\n‚úÖ All models trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa580bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Evaluation Results:\n",
      "            Target             Model       MSE        R2\n",
      "5   Area harvested      RandomForest  0.015408  0.998346\n",
      "7   Area harvested           XGBoost  0.020844  0.997762\n",
      "4   Area harvested               ANN  0.032210  0.996542\n",
      "6   Area harvested  LinearRegression  0.042174  0.995473\n",
      "1       Production      RandomForest  0.005827  0.999393\n",
      "3       Production           XGBoost  0.010073  0.998951\n",
      "2       Production  LinearRegression  0.041392  0.995688\n",
      "0       Production               ANN  0.061595  0.993583\n",
      "9            Yield      RandomForest  0.026414  0.986472\n",
      "8            Yield               ANN  0.031133  0.984056\n",
      "11           Yield           XGBoost  0.031472  0.983882\n",
      "10           Yield  LinearRegression  0.042631  0.978167\n"
     ]
    }
   ],
   "source": [
    "# === Summary table ===\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=[\"Target\", \"R2\"], ascending=[True, False])\n",
    "print(\"\\nüìä Model Evaluation Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8ead31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Repository created or already exists: syazayacob/crop_models\n",
      "‚úÖ Uploaded: Area harvested_ANN.h5\n",
      "‚úÖ Uploaded: Area harvested_ANN_scaler.pkl\n",
      "‚úÖ Uploaded: Area harvested_LinearRegression.pkl\n",
      "‚úÖ Uploaded: Area harvested_RandomForest.pkl\n",
      "‚úÖ Uploaded: Area harvested_XGBoost.pkl\n",
      "‚úÖ Uploaded: Production_ANN.h5\n",
      "‚úÖ Uploaded: Production_ANN_scaler.pkl\n",
      "‚úÖ Uploaded: Production_LinearRegression.pkl\n",
      "‚úÖ Uploaded: Production_RandomForest.pkl\n",
      "‚úÖ Uploaded: Production_XGBoost.pkl\n",
      "‚úÖ Uploaded: Yield_ANN.h5\n",
      "‚úÖ Uploaded: Yield_ANN_scaler.pkl\n",
      "‚úÖ Uploaded: Yield_LinearRegression.pkl\n",
      "‚úÖ Uploaded: Yield_RandomForest.pkl\n",
      "‚úÖ Uploaded: Yield_XGBoost.pkl\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, upload_file, create_repo\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "create_repo(\"syazayacob/crop_models\", repo_type=\"model\", token=HF_TOKEN)\n",
    "\n",
    "REPO_ID = \"syazayacob/crop_models\"\n",
    "\n",
    "# Corrected create_repo call\n",
    "api = HfApi()\n",
    "try:\n",
    "    api.create_repo(repo_id=REPO_ID, token=HF_TOKEN, repo_type=\"model\", exist_ok=True)\n",
    "    print(f\"‚úÖ Repository created or already exists: {REPO_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create repo: {e}\")\n",
    "\n",
    "# Adjust this path to match where your files are stored\n",
    "model_folder = \"../models\"\n",
    "\n",
    "model_files = [\n",
    "    \"Area harvested_ANN.h5\",\n",
    "    \"Area harvested_ANN_scaler.pkl\",\n",
    "    \"Area harvested_LinearRegression.pkl\",\n",
    "    \"Area harvested_RandomForest.pkl\",\n",
    "    \"Area harvested_XGBoost.pkl\",\n",
    "    \"Production_ANN.h5\",\n",
    "    \"Production_ANN_scaler.pkl\",\n",
    "    \"Production_LinearRegression.pkl\",\n",
    "    \"Production_RandomForest.pkl\",\n",
    "    \"Production_XGBoost.pkl\",\n",
    "    \"Yield_ANN.h5\",\n",
    "    \"Yield_ANN_scaler.pkl\",\n",
    "    \"Yield_LinearRegression.pkl\",\n",
    "    \"Yield_RandomForest.pkl\",\n",
    "    \"Yield_XGBoost.pkl\"\n",
    "]\n",
    "\n",
    "# Upload with corrected file paths\n",
    "for filename in model_files:\n",
    "    full_path = os.path.join(model_folder, filename)\n",
    "    if os.path.exists(full_path):\n",
    "        try:\n",
    "            upload_file(\n",
    "                path_or_fileobj=full_path,\n",
    "                path_in_repo=filename,\n",
    "                repo_id=REPO_ID,\n",
    "                repo_type=\"model\",\n",
    "                token=HF_TOKEN\n",
    "            )\n",
    "            print(f\"‚úÖ Uploaded: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to upload {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
